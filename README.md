# Projekt: Steuerung mit Handbewegungen

Praktikum 2 Computer Vision
Hochschule Darmstadt, SS 2024
Prof. Dr. Elke Hergenröther

### Teammitglieder: Anh Vu (1129004), Hannah Schult (1129010)

### Introduction:

In der heutigen digitalen Welt sind intuitive Benutzeroberflächen für die Interaktion mit technologischen Geräten von entscheidender Bedeutung. Handgesten-Erkennungssysteme spielen eine Rolle bei der Schaffung der Benutzererfahrungen. Diese Technologie ermöglicht es, durch einfache Handbewegungen intuitive Aufgaben auszuführen

### Zielsetzung:

Ziel ist es, Verfahren zu entwickeln, welche menschliche Handgesten mittels Kameras effizient erkennen. Dabei wird zunächst ein eigenständig entwickelter Ansatz (Ansatz A) vorgestellt, gefolgt von der Implementierung eines vorgefertigten Frameworks, MediaPipe (Ansatz B). Durch den Vergleich dieser beiden Methoden sollen die Stärken und Schwächen jedes Ansatzes aufgezeigt und Ansätze zur weiteren Optimierung der Handgestenerkennung erörtert werden.

### Ordnerstruktur:

- Projektpaper (Paper Praktikum 2)
- Präsentation (CV_Projekt_2.pptx)
- Quellcode:
  1. ./src/cnn: Notebook zum 1. Ansatz + LiveDemo
  2. ./src/mediapipe: Notebook zum 2. Ansatz

### Referenzen/ Inspiration:

- 1. Ansatz (traniertes CNN-Modell)
  - https://techvidvan.com/tutorials/hand-gesture-recognition-tensorflow-opencv/
  - https://link.springer.com/article/10.1007/s11760-023-02626-8#Sec3
  - https://www.youtube.com/watch?v=Ia0tjqW7xKA: mit CNN (Code in der Beschreibung verlinkt)
  - https://www.kaggle.com/code/sarjit07/hand-gestures-recognition-with-opencv-and-cnn: Auch mit CNN
  - Datensatz: https://www.kaggle.com/datasets/sarjit07/hand-gesture-recog-dataset/data
- 2. Ansatz (MediaPipe)
  - (tbd)
