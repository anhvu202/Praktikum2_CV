{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handgestensteuerung mit MediaPipe-Modul\n",
    "\n",
    "### Um mit diesem Code den Laptop freihändig zu bedienen (= Bild vergrößern / verkleinern und nächstes Bild anschauen) muss der Code gestartet werden. Die Kamera muss offen sein und es muss bspw. ein Browserfenster geöffnet sein, indem Bilder offen sind. In das Browserfenster muss geklickt werden, damit die Befehle ausgeführt werden können.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "\n",
    "# Initialisiere Mediapipe Hand-Modul\n",
    "mp_hands = mp.solutions.hands  # Mediapipe Hand-Modul initialisieren\n",
    "hands = mp_hands.Hands()  # Hand-Erkennung instanziieren\n",
    "mp_drawing = mp.solutions.drawing_utils  # Zeichen-Utilities von Mediapipe initialisieren\n",
    "\n",
    "# Öffne die Kamera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Zustandsvariable zur Verfolgung der zuletzt ausgeführten Aktion\n",
    "last_action = None\n",
    "\n",
    "def finger_up(landmarks, finger_tip, finger_dip):\n",
    "    \"\"\"Prüfe, ob der Finger gestreckt ist\"\"\"\n",
    "    return landmarks[finger_tip].y < landmarks[finger_dip].y #prüfen, ob finger_dip über finger_tip\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read() #Liest ein Bild von der Kamera ein\n",
    "    if not ret:\n",
    "        break #wenn kein Bild gelesen werden kann, Schleife beenden\n",
    "\n",
    "    # Bild horizontal spiegeln, damit es nicht spiegelverkehrt ist\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "\n",
    "    # Bild von BGR zu RGB konvertieren\n",
    "    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)  #Konvertiere das Bild von BGR zu RGB (Mediapipe benötigt RGB)\n",
    "    image.flags.writeable = False  #Bild als nicht schreibbar markieren, um Performance zu verbessern\n",
    "    results = hands.process(image)  #Verarbeite das Bild mit Mediapipe Hand-Modul\n",
    "    image.flags.writeable = True  #Bild wieder als schreibbar markieren\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  #Konvertiere das Bild zurück zu BGR für OpenCV\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        # Wenn Handlandmarken erkannt wurden\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(image, hand_landmarks, mp_hands.HAND_CONNECTIONS) # Zeichne Handlandmarken auf das Bild\n",
    "            \n",
    "            # Prüfen der Fingerzustände\n",
    "            landmarks = hand_landmarks.landmark\n",
    "            index_finger_up = finger_up(landmarks, mp_hands.HandLandmark.INDEX_FINGER_TIP, mp_hands.HandLandmark.INDEX_FINGER_DIP) #gestrechter Zeigefinger\n",
    "            middle_finger_up = finger_up(landmarks, mp_hands.HandLandmark.MIDDLE_FINGER_TIP, mp_hands.HandLandmark.MIDDLE_FINGER_DIP) #gestreckter Mittelfinger\n",
    "            pinky_finger_up = finger_up(landmarks, mp_hands.HandLandmark.PINKY_TIP, mp_hands.HandLandmark.PINKY_DIP) #gestreckter kleiner Finger\n",
    "            \n",
    "            if index_finger_up and middle_finger_up and not pinky_finger_up:\n",
    "                if last_action != 'zoom_in':\n",
    "                    pyautogui.hotkey('ctrl', '+')  # Vergrößern des Bildes (z.B. in einem Browser oder Bildbetrachter)\n",
    "                    last_action = 'zoom_in'\n",
    "            elif pinky_finger_up and not index_finger_up and not middle_finger_up:\n",
    "                if last_action != 'zoom_out':\n",
    "                    pyautogui.hotkey('ctrl', '-')  # Verkleinern des Bildes (z.B. in einem Browser oder Bildbetrachter)\n",
    "                    last_action = 'zoom_out'\n",
    "            elif index_finger_up and not middle_finger_up:\n",
    "                if last_action != 'next_slide':\n",
    "                    pyautogui.press('right')  # Nächste Folie in PowerPoint / nächstes Bild \n",
    "                    last_action = 'next_slide'\n",
    "            else:\n",
    "                last_action = None  # Reset der Aktion, wenn keine Gesten erkannt werden\n",
    "\n",
    "    cv2.imshow('Hand Gesture Recognition', image)\n",
    "\n",
    "    if cv2.waitKey(5) & 0xFF == 27:\n",
    "        break # Beende die Schleife, wenn die ESC-Taste gedrückt wird\n",
    "\n",
    "cap.release()  # Kamera freigeben\n",
    "cv2.destroyAllWindows()  # Alle OpenCV-Fenster schließen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
